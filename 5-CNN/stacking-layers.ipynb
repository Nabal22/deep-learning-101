{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec84f4c",
   "metadata": {},
   "source": [
    "# Stacking layers\n",
    "_From [Dataflowr Module 5](https://dataflowr.github.io/website/modules/5-stacking-layers/) by Marc Lelarge_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8784f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c24730d",
   "metadata": {},
   "source": [
    "In TP-3, you implemented an MLP using PyTorch's `nn.Sequential`.\n",
    "\n",
    "This works well for a simple sequence of operations, but for any model of reasonable complexity, it's best to write a subclass of `torch.nn.Module`.\n",
    "\n",
    "Here is the same model written as a `torch.nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = torch.nn.Sequential(nn.Linear(2, 50), nn.ReLU(), nn.Linear(50, 1), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a791b2c8",
   "metadata": {},
   "source": [
    "This is possible of a simple sequence of operations, but for any model of reasonable complexity, the best is to write a sub-class of `torch.nn.Module`.\n",
    "\n",
    "Here is the same model written as a `torch.nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=2, out_features=50)\n",
    "        self.fc2 = nn.Linear(in_features=50, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726e9b02",
   "metadata": {},
   "source": [
    "Inheriting from `torch.nn.Module` provides many mechanisms implemented in the superclass.\n",
    "\n",
    "First, the `__call__` operator is redefined to call the forward method and run additional operations. The forward pass should thus be executed through this operator and not by calling forward explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "input = torch.empty(12, 2).normal_()\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0407a7",
   "metadata": {},
   "source": [
    "All Parameters added as class attributes are seen by Module.parameters().\n",
    "\n",
    "As long as you use autograd-compliant operations, the backward pass is implemented automatically.\n",
    "\n",
    "This is crucial to allow the update of the Parameters with your optimizer.\n",
    "\n",
    "With a loss and an optimizer the training loop can use the usual four steps:\n",
    "- forward\n",
    "- loss\n",
    "- backward\n",
    "- step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4cea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "label = torch.zeros(12, 1)\n",
    "\n",
    "output = model(input)\n",
    "loss = loss_fn(output, label)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fabbcb",
   "metadata": {},
   "source": [
    "Now it's time to build more complex architectures!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025-m2-idl (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
